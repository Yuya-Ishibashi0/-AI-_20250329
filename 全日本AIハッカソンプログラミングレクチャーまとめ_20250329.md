
### 1. AIとは何か？ - 概念と比喩

- **AI（人工知能）とは**：人間の知的活動（学習、推論、判断など）をコンピュータで模倣しようとする技術や学問分野のことです。
    
- **比喩：自動車と運転**
    - 昔は、AIの基盤技術（＝自動車を作ること）を開発するのは非常に難解でした。
    - しかし、「**深層学習（ディープラーニング）**」の登場により、AIを利用すること（＝自動車を運転すること）が格段に容易になりました。多くの人がAI技術の恩恵を受けられるようになったのです。
    - かつて「AIはよくわからないもの」という印象がありましたが、深層学習によってその仕組みや応用が理解しやすくなりました。
- **画像案1**: 複雑な自動車エンジンの設計図と、楽しそうに車を運転している人のイラストを並べる。キャプション「作る（AI基礎研究）のは大変だったが、使う（深層学習の応用）のは身近になった」。
    ![[Pasted image 20250329113113.png]]

### 2. AIの学習の基本：データから学ぶ仕組み

- **基本原理**: AIは、大量のデータ（入力）を学習し、そのデータに含まれるパターンや特徴を捉えます。そして、その学習結果をもとに、新しいデータ（出力）を生成したり、分類したりします。
    
- **学習プロセス**:
    
    1. **入力**: AIにデータを与える。
    2. **AI処理**: AIが内部の計算（モデル）を通して出力を生成する。
    3. **出力**: AIが生成した結果。
    4. **比較と調整**: AIの出力と「望ましい出力（正解データ）」を比較し、その**差（Loss / 誤差）**を計算します。
    5. **最小化**: AIはこの「差（Loss）」がなるべく小さくなるように、内部の計算方法（パラメータ）を少しずつ調整していきます。この調整プロセスを繰り返すことで、AIは賢くなっていきます。
- **比喩：コップの水**
    
    - 1Lの水を正確に測り取りたい（＝望ましい出力）。
    - 最初に適当な容器（＝AIモデル）で水を汲むと、1Lぴったりではないかもしれない（＝初期出力）。
    - 望ましい1Lとの差を見て、容器の形を変えたり（＝パラメータ調整）、汲み方を変えたりして、1Lに近づけていくイメージです。
    - （メモの「3Lの深さ～」の部分は、もしかすると、データの特徴量をうまく捉えるための工夫（例：次元削減や特徴抽出）の比喩かもしれません。不要な部分を取り除き、本質的な「1L」分だけを取り出すようなイメージです。）
- この調整プロセスは、数学的な計算（主に微分）によって効率的に行われます。
    
- **画像案2**: 「入力データ」→「AI（ブラックボックス）」→「出力データ」という図。その横に「望ましい出力」を置き、「出力データ」と「望ましい出力」の差を「Loss」として表示。Lossを最小化するように「AI」へフィードバックする矢印を追加する。
	![[Pasted image 20250329113135.png]]

- **画像案3**: Loss（誤差）が学習の反復（エポック）とと![[Pasted image 20250329113140.png]]もに減少していくグラフ。
    

### 3. オートエンコーダーと赤ちゃんの学習

- **オートエンコーダー**: AIアーキテクチャの一種。入力データを一度圧縮（エンコード）し、その後、元のデータに復元（デコード）しようとします。この過程で、データの本質的な特徴量を捉えることを学習します。
    
- **比喩：赤ちゃん**
    
    - 赤ちゃんは、「黄色い」「棒状」「曲がっている」といった特徴を理論的に教わるのではなく、様々な物を見る経験を通して、「なんとなく」物事を分類し始めます。
    - 何度もバナナを見るうちに、それらの特徴を統合し、「これがバナナだ」と特定できるようになります。
    - AIの学習、特に画像解析などはこれに似ており、大量のデータから「なんとなく」パターンを見つけ出し、徐々に精度を高めていきます。明示的なルールを教えなくても学習が進む点が特徴です。
- **画像案4**: 標準的なオートエンコーダーの構造図（入力 → Encoder → 潜在変数 (Latent) → Decoder → 出力）。
    ![[Pasted image 20250329113147.png]]
- **画像案5**: 赤ちゃんが色々な果物を見ているイラスト。その中からバナナを指差して認識している様子。
    ![[Pasted image 20250329113154.png]]

### 4. 生成AIとは何か？

- **生成AI**: 学習したデータに基づいて、**新しい**データ（文章、画像、音楽、コードなど）を**生成**することに特化したAIの一分野です。
    
- **AIとの関係**: 生成AIはAIの一部です。AIが行うタスクには様々な複雑さがあります。
    
    - **分類**: 比較的単純（例：手書き数字0〜9の分類 - 10次元程度）
    - **認識**: より複雑（例：犬か猫かの認識 - 数千次元程度）
    - **生成**: 非常に複雑（例：質問応答、画像生成 - 数億〜数千億次元以上、ChatGPTなど）
- 次元数が大きいほど、扱える情報の組み合わせが多く、より高度で創造的なタスクが可能になります。
    
- **画像案6**: AIのタスクを複雑さ（次元数）のスケールで表示。左端に「分類（数字認識）」、中間に「認識（犬/猫）」、右端に「生成（テキスト/画像）」を配置し、次元数の目安（10, 1000, 1億+）を添える。
    ![[Pasted image 20250329113213.png]]

### 5. なぜAIは急速に進化したのか？ - GPUの役割

- **GPU (Graphics Processing Unit)** の進化と低価格化が、AI（特に深層学習）の発展を大きく後押ししました。
    
- GPUはもともとゲームなどの画像処理用に開発されましたが、単純な計算を**並列**に大量にこなす能力が、深層学習の膨大な計算に非常に適していました。
    
- ゲーム産業の発展（メモのセガ社長とNVIDIAの逸話もこの文脈の一部かもしれません）がGPUの性能向上と普及を促し、結果的にAI研究者や開発者が高性能な計算資源を手に入れやすくなったことが、近年のAIブームの大きな要因です。
    
- **ゴスパラさん**: おそらく講義中に言及されたAI分野の著名な研究者（例：Hinton氏など）か、特定の人物を指していると思われますが、メモだけでは特定困難です。
    
- **画像案7**: 最新のGPUカードの写真、またはGPUの並列処理のイメージ図。隣にAIの進化を示す年表などを添える。
    ![[Pasted image 20250329113651.png]]

### 6. AIモデルのカスタマイズと効率化

- **追加学習（ファインチューニング）**:
    
    - 既に大規模なデータで学習済みの汎用的なAIモデル（ベースモデル）を用意します。
    - そのモデルに、特定のタスクに関連する**追加のデータ**を少量学習させることで、そのタスクに特化した性能の高いモデルを作成する手法です。ゼロから学習させるよりも効率的です。
- **LoRA (Low-Rank Adaptation)**:
    
    - ファインチューニングの一種ですが、モデル全体のパラメータを調整するのではなく、ごく一部のパラメータ（低ランク行列）だけを追加・調整する**効率的な**手法です。
    - これにより、計算コストやメモリ使用量を大幅に削減しながら、モデルの性能を特定のタスクに適応させることができます。（「全体のチューニング？ついていけない」というメモは、通常のファインチューニングのリソース要求の高さを反映しており、LoRAのような手法の利点を示唆しています。）
- **量子化**:
    
    - AIモデルが内部で持つ数値（重みパラメータ）の精度を意図的に下げる（例：32ビット浮動小数点数を8ビット整数にする）ことで、モデルのファイルサイズを小さくし、計算速度を向上させる技術です。
    - これにより、限られたメモリ容量（例：24GB VRAM）でも、比較的高性能なAIモデルを動かすことが可能になります。
- **画像案8**: 「ベースモデル」＋「追加データ」→「ファインチューニング」→「特化モデル」という流れ図。
    ![[Pasted image 20250329122204.png]]
- **画像案9**: 通常のファインチューニング（モデル全体を調整）とLoRA（一部の小さなアダプタ層を調整）の比較図。 
	![[Pasted image 20250329122303.png]]

- **画像案10**: 高精度な数値（例: 3.14159265）が、量子化によって低精度な数値（例: 3.14 or 8bit整数）に変換されるイメージ図。
	![[Pasted image 20250329122559.png]]
### 7. 生成AIのクリエイティブな活用

- 生成AIは、画像、動画、音楽、プログラムコードなど、様々なクリエイティブなコンテンツ制作に応用されています。
    
- **画像生成の仕組み**: 基本的には他のAIと同様、「目標（例：テキストによる指示）」と「生成された画像」の間のギャップ（Loss）を最小化するように学習・生成します。テキスト指示（プロンプト）に基づいて画像を生成するモデルが主流です。
    
- **ワークフロー例**:
    
    1. テキストプロンプト等で**画像を生成**する。
    2. 生成された画像を、**Image-to-Video**技術（例：Motion Brushなど）を使って**動画**にする。
- 動画生成技術も急速に進歩しており、オープンソースのモデルも登場しています。
    
- **リソース要件**: 一部の画像・動画生成モデルは、比較的手頃なGPU（例：24GB VRAM）でも動作可能になってきており、これは大規模言語モデル（LLM）が要求する膨大なメモリ（例：128GB以上）と比べるとアクセスしやすい点です。
    
- **画像案11**: AIが生成した美しい画像、動画の一場面、楽譜、コードスニペットなどを並べたコラージュ。
    ![[Pasted image 20250329123929.png]]
- **画像案12**: 「テキストプロンプト」→「画像生成AI」→「生成画像」→「Image-to-Video AI」→「生成動画」というワークフロー図。
    ![[Pasted image 20250329124110.png]]

---
20250329 Yuya Ishibashi